---
title: "The Unbundling of Work or: How I Learned to Stop Worrying and Let AI Take My Tasks"
date: 2026-01-19
status: published
tags: [ai, work, automation, economics, labor]
image: /assets/images/headers/unbundling-of-work-header.png
---

You blocked three hours for the task. Deep work, no meetings. You're kind of dreading it. It's the kind of work that needs doing but doesn't spark joy. On a whim, you decide to see if AI can help. You write a prompt, hit enter, watch it think.

It finishes in minutes. The output is good. Really good. You stretch, victorious, already planning what to do with your reclaimed afternoon.

Then the second thought arrives: *that's what they pay me for.*

The magic trick gets less fun after that.

## Your Job Is a Label, Not a Unit

That second thought lingers. You start noticing things. The task AI just handled? You've done it hundreds of times. It's part of your job, but you know it's not the whole thing. There's so much that goes around that task that it's merely a cog in a larger machine. There's the part where you figure out *what* needs doing. The part where you explain the results to someone who doesn't get it. The part where you make the call when the data isn't clear.

Your job isn't one thing. It's a bundle of things wearing a single title. "Software engineer" can be 80% writing code at one company and 80% meetings and architecture at another. "Financial analyst" can be 80% spreadsheets at one firm and 80% client calls at another. The title is a convenient fiction. The work is what fills your days.

AI doesn't automate jobs. It automates tasks. Once you see your work as a bundle, the question shifts: which tasks can AI do, and what's left when they're gone?

## We've Seen This Before

This isn't the first time technology came for the tasks inside a job. The ATM was supposed to kill bank tellers. Instead, something strange happened: ATMs [reduced the number of tellers per branch from 20 to 13](https://www.imf.org/external/pubs/ft/fandd/2015/03/bessen.htm), but that made branches cheaper to operate. Banks opened more branches. Teller employment actually *grew* for decades. The job shifted from counting cash to relationship banking. The tasks changed; the job survived.

But the story has an ending. Teller wages have [dropped about 25%](https://www.burningglassinstitute.org/bginsights/the-case-of-the-vanishing-teller-how-bankings-entry-level-jobs-are-transforming) since the early 2010s. Employment is declining. The job title survives, but the economics underneath have eroded. The ATM didn't kill the teller. It just took forty years to finish the job.

Then there are the telephone operators. At peak, 350,000 of them, almost all women, connecting calls by hand. Today, fewer than 5,000. The job didn't transform. It disappeared. But it took 86 years from the first automated switchboard to the last manual one.

The lesson isn't "automation kills jobs" or "automation saves jobs." Automation affects tasks first, employment later. The question is: how much later? Telephone operators had decades. We might have years.

## But Some Jobs Really Are Just Tasks

Some jobs really are mostly automatable tasks stacked on top of each other. If the "kernel of irreducible humanness" in your role is too small, the job doesn't transform. It deflates. Or disappears entirely.

The carpenter analogy is comforting. Power tools didn't kill carpenters; they made them more efficient. But that story has survivor bias baked into it. Carpentry survived. Telephone operators didn't. The question isn't whether *some* jobs survive automation, but whether *yours* is more like the carpenter or the switchboard operator.

Middle management is already finding out. [Job postings for middle management have dropped over 40%](https://fortune.com/2025/10/29/amazon-layoffs-ai-middle-managers-robots-factory-workers/) since 2022. Amazon, Salesforce, and others are making explicit cuts, citing AI tools that handle coordination, reporting, and information flow. A lot of middle management turned out to be the human API layer between people who make decisions and people who execute them. AI is a very efficient API.

You know this layer. You've worked with people whose value was orchestration: forwarding emails to the right person, sitting in meetings so they can update other meetings, explaining what engineering said to the business folks (and vice versa), being the person you have to go through to get anything approved. That's not a criticism. They were doing real work. But the work existed because humans were the only technology available for it. In an organization where AI can summarize, route, translate, and coordinate, that layer looks expensive for what it delivers.

Speed matters too. Telephone operators had 86 years to adapt. If AI compresses the same transformation into five or ten years, the "jobs transform" story might be technically true but socially catastrophic. People can't retrain that fast. Institutions can't adapt that fast. The pattern holds, but the timeline breaks everything.

## What I've Seen: The Software Engineering Sandwich

I'm a software engineer, so I've watched this happen to my own work in real time.

The old loop was simple: gather requirements, implement code, test. That middle part was where most of the time went. It was the job. Now the first and last phases have grown while the middle has shrunk. Requirements and testing sandwich the implementation. It's becoming more important to state what you want clearly and verify that you got it than to write the code yourself.

This doesn't mean I'm less of an engineer. It means I focus on different parts: architecture, workflows, tradeoffs when the answer isn't obvious, judgment calls that require context AI doesn't have. The tasks shifted; the job survived. If anything, I spend more time on the parts I actually care about.

I see the same pattern elsewhere. Financial analysts spending less time building models and more time interpreting them for clients. Lawyers using AI for discovery and focusing on strategy. Software engineering is just the easiest to see because the tools are so visible. But the sandwich is everywhere: the human parts on either end, the automated parts in the middle.

Here's what's stranger: jobs don't just shrink. They also merge. The developer who used to need a designer can now design. The designer who used to need a developer can now ship. The financial analyst who used to need a data science team can now train and run their own models. AI bridges skill gaps that used to require collaboration. Work that took two people can now be done by one person with AI. That's fewer jobs in one sense, but richer, more complete roles for the people who remain.

The optimist says: I'll do the interesting parts and AI will handle the boring parts. The pessimist asks: what if someone else's interesting parts were your entire job?

## Two Reasons for Optimism (That Aren't Cope)

That pessimist's question is real. Some jobs are just tasks. The timeline might be brutal. Middle management is already getting squeezed. But I'm actually optimistic, and not in a "don't worry, it'll be fine" way. There are two real reasons to think the story ends better than the anxiety suggests.

**The jagged frontier.** AI isn't uniformly good at everything. It's shockingly capable at some tasks and weirdly bad at others, and the boundary between them is jagged, not smooth. Your job survives if enough of your tasks fall on the human side of that frontier. The more judgment, context, and ambiguity involved, the more likely you're safe. For now.

**The accountability gap.** Even when AI *can* do something, people often still want a human involved. I can get my lab results analyzed by a very smart AI. But I also want a doctor to look at them, to weigh in, to be the one I can ask questions. Someone needs to be accountable. Someone needs to own the decision. For high-stakes work, that's durable demand for humans.

These aren't permanent shields. The frontier moves. Trust builds over time. But "for now" might be a long time, especially for work involving risk, relationships, or responsibility. The question is whether you're paying attention to where the frontier is today and where it's heading.

## Map Your Own Frontier

The jagged frontier isn't a fixed line on a map. It moves. And the only way to know where it is for *your* work is to use the tools yourself.

People who avoid AI because "it can't do my job" are missing the point. They're not protecting themselves; they're staying ignorant of their own vulnerabilities. The frontier moves whether you're watching or not. The question is whether you'll be surprised when it reaches you.

Think of it like golf clubs. An iron, a driver, a wood: all great, but not at the same tasks. Mastery isn't about having one club. It's knowing which one fits which shot. The same is true for AI. You need to know what it does well, what it does badly, and where you add value that it can't.

Here's a practical suggestion: audit your own task bundle. Spend a week tracking what you actually do. Categorize each task: "AI could do this now," "AI could probably do this in two years," "this probably still needs me." Be honest. The percentage breakdown will either reassure you or alarm you, but either way you'll have a clearer picture of where you stand.

---

Are you more than the sum of your tasks?

The honest answer: you won't know until you test the boundary. Some of what you do will turn out to be automatable. Some won't. The ratio matters, and so does what you do with what's left.

Jobs don't get eliminated in the long run. They get transformed. But transformation isn't something that happens to you. It's something you participate in, or don't. The people who thrive will be the ones who mapped their frontier early, figured out where they actually add value, and leaned into that. The ones who get caught off guard will be the ones who never looked.
