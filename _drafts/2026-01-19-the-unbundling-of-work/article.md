---
title: "The Unbundling of Work: Why AI Won't Kill Your Job, Just Reorganize It"
date: 2026-01-19
status: draft
tags: [ai, work, automation, economics, labor]
---

You blocked three hours for the task. Deep work, no meetings. You're kind of dreading it, if you're honest. It's the kind of work that needs doing but doesn't spark joy. On a whim, you decide to see if AI can help. You write a prompt, hit enter, watch it think.

It finishes in minutes. The output is good. Really good. You stretch, victorious, already planning what to do with your reclaimed afternoon.

Then the second thought arrives: *that's what they pay me for.*

The magic trick gets less fun after that.

## Your Job Is a Label, Not a Unit

That second thought lingers. You start noticing things. The task AI just handled? You've done it hundreds of times. It's part of your job but, to be honest (and you know this), it's not the whole thing. There's so much that goes around that task that it's merely a cog in a larger machine. There's the part where you figure out *what* needs doing. The part where you explain the results to someone who doesn't get it. The part where you make the call when the data isn't clear.

Your job isn't one thing. It's a bundle of things wearing a single title. "Software engineer" can be 80% writing code at one company and 80% meetings and architecture decisions at another. "Financial analyst" can be 80% spreadsheets at one firm and 80% client calls at another. The title is a convenient fiction. The work is what actually fills your days.

And AI doesn't automate jobs. It automates tasks. Once you see your work as a bundle rather than a single block, the question changes. It's not "Will AI take my job?" It's "Which tasks in my bundle can it do, and what's left when they're gone?"

## We've Seen This Before

This isn't the first time a technology came for the tasks inside a job. The ATM was supposed to kill bank tellers. Instead, something strange happened: ATMs reduced the number of tellers needed per branch from 20 to 13, but that made branches cheaper to operate. Banks opened more branches. Teller employment actually *grew* for decades. The job shifted from counting cash to selling financial products and managing customer relationships. The tasks changed; the job survived.

But here's the part that doesn't make the optimistic version of the story: it's reversing now. Teller wages have dropped about 25% since the early 2010s. Employment is declining. The job title survives, but the economics underneath it have eroded. The ATM didn't kill the teller. It just took forty years to finish the job.

Then there are the telephone operators. At peak, 350,000 of them, almost all women, connecting calls by hand. Today, fewer than 5,000. The job didn't transform. It disappeared. But it took 86 years from the first automated switchboard to the last manual one. That's a long time to adapt.

The lesson isn't "automation kills jobs" or "automation saves jobs." It's that automation affects tasks first, employment later. The question is always: how much later? The telephone operators had decades. We might have years.

## But Some Jobs Really Are Just Tasks

Here's where I have to be honest with you: some jobs really are mostly automatable tasks stacked on top of each other. If the "kernel of irreducible humanness" in your role is too small, the job doesn't transform. It deflates. Or it disappears entirely.

The carpenter analogy is comforting. Power tools didn't kill carpenters; they made them more efficient. But that story has survivor bias baked into it. Carpentry survived. Telephone operators didn't. The question isn't whether *some* jobs survive automation. It's whether *yours* is more like the carpenter or more like the switchboard operator.

Middle management is already finding out. Job postings for middle management roles have dropped over 40% since 2022. Amazon, Salesforce, and others are making explicit cuts, citing AI tools that handle coordination, reporting, and information flow. A lot of middle management turned out to be the human API layer between people who make decisions and people who execute them. AI is a very efficient API.

You know this layer. Let me explain what I mean. You've worked with people whose value was orchestration: forwarding emails to the right person, sitting in meetings so they can update other meetings, explaining what engineering said to the business folks (and vice versa), being the person you have to go through to get anything approved. That's not a criticism of those people. They were doing real work. But the work existed because humans were the only technology available for it. In an organization where AI can summarize, route, translate, and coordinate, that layer starts to look expensive for what it delivers.

And speed matters. The telephone operators had 86 years to adapt. If AI compresses that same transformation into five or ten years, the "jobs transform" story might be technically true but socially catastrophic. People can't retrain that fast. Institutions can't adapt that fast. The pattern holds, but the timeline breaks everything.

## What I've Seen: The Software Engineering Sandwich

I'm a software engineer, so I've watched this happen to my own work in real time.

The old loop was simple: gather clean requirements, implement code, test. That middle part, the implementation, was where most of the time went. It was the job. Now? The first and last phases have grown while the middle has shrunk. Requirements and testing sandwich the implementation. It's becoming more important to state what you want clearly and verify that you got it than to actually write the code yourself.

This doesn't mean I'm less of an engineer. It means I focus on different parts. Architecture decisions. Organizing workflows. Weighing tradeoffs when the answer isn't obvious. Making the judgment calls that require context AI doesn't have. The tasks shifted; the job survived. If anything, I spend more time on the parts I actually care about.

I see the same pattern in other professions. Financial analysts spending less time building models and more time interpreting them for clients. Lawyers using AI for discovery and focusing on strategy. Software engineering is just the easiest to see because the tools are so visible. But the sandwich is everywhere: the human parts on either end, the automated parts in the middle.

## Two Reasons for Optimism (That Aren't Cope)

So far this sounds grim. Some jobs are just tasks. The timeline might be brutal. Middle management is already getting squeezed. But I'm actually optimistic, and not in a "don't worry, it'll be fine" way. There are two real reasons to think the story ends better than the anxiety suggests.

**The jagged frontier.** AI isn't uniformly good at everything. It's shockingly capable at some tasks and weirdly bad at others, and the boundary between them is jagged, not smooth. Your job survives if enough of your tasks fall on the human side of that frontier. The more judgment, context, and ambiguity involved, the more likely you're safe. For now.

**The accountability gap.** Even when AI *can* do something, people often still want a human involved. I can get my lab results analyzed by a very smart AI. But I also want a doctor to look at them, to weigh in, to be the one I can ask questions. It's not that AI is wrong. It's that someone needs to be accountable. Someone needs to own the decision. For high-stakes work, that's durable demand for humans.

These aren't permanent shields. The frontier moves. Trust builds over time. But "for now" might be a long time, especially for work that involves risk, relationships, or responsibility. The question is whether you're paying attention to where the frontier is today and where it's heading.

<!-- Section 7: Map Your Own Frontier — PENDING -->

<!-- Section 8: Close — PENDING -->
