# Research: Harvard/BCG "Jagged Frontier" Study

*Researched: 2026-02-02*

## Summary

A 2023 field experiment with 758 Boston Consulting Group consultants found that AI dramatically improved performance on tasks within its capabilities (+40% quality, +25% speed) but *decreased* performance when used for tasks outside its capabilities. The study coined the term "jagged technological frontier" to describe AI's uneven competence, and found that novices were more likely to be harmed by AI use than experts who could identify and reject flawed suggestions.

---

## Key Findings

### 1. The Core Performance Numbers

**Finding:** Consultants using AI finished 12.2% more tasks on average, completed tasks 25.1% more quickly, and produced 40% higher quality results than those without AI.

- **Source:** [Harvard D3 Institute - A New Paradigm for Skill Development](https://d3.harvard.edu/a-new-paradigm-for-skill-development-a-large-scale-bcg-experiment/)
- **Credibility:** High (Harvard Business School field experiment, peer-reviewed)
- **How to use:** These are the headline numbers—AI provides massive productivity gains *within the frontier*.

### 2. The "Jagged Frontier" Concept

**Finding:** AI doesn't make people uniformly better or worse at their jobs. Instead, it creates a "jagged technological frontier"—a boundary where some tasks are easily accomplished by AI while others, though seemingly similar in difficulty, lie completely outside its current capabilities.

- **Source:** [HBS Working Paper - Navigating the Jagged Technological Frontier](https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf)
- **Credibility:** High (original research paper)
- **How to use:** This is the core insight for the article—you need judgment to know which tasks AI can handle. New entrants don't have this judgment.

### 3. The Danger Outside the Frontier

**Finding:** For tasks "outside the frontier," researchers observed a performance *decrease* because people would "kind of switch off their brains and follow what AI recommends," which was more likely to be incorrect.

- **Source:** Multiple coverage of the study
- **Credibility:** High
- **How to use:** This is the mechanism for the new-entrant paradox. Without domain knowledge, you can't identify when AI is wrong. You follow bad advice.

### 4. The Novice vs. Expert Gap

**Finding:** While AI leveled the performance of junior consultants on within-frontier tasks, its use at the jagged frontier where AI was unreliable caused novices to experience a **19-percentage-point performance drop**, while experts who could identify and disregard flawed suggestions succeeded.

- **Source:** [EDRM Report on the Experiment](https://edrm.net/2024/04/report-on-the-first-scientific-experiment-to-test-the-impact-of-generative-ai-on-complex-knowledge-intensive-work/)
- **Credibility:** High
- **How to use:** **This is the critical data point.** Novices got *worse* when AI was unreliable. This directly supports the new-entrant paradox—lacking expertise, they couldn't reject bad suggestions.

### 5. The Skill Leveling Effect (Within Frontier)

**Finding:** AI works as a skill leveler for within-frontier tasks. The consultants who scored worst at the start had the biggest performance jump (43%) when using AI. Top consultants still improved, but less dramatically.

- **Source:** [Mi3 Coverage](https://www.mi-3.com.au/20-09-2023/harvard-business-school-study-bcg-finds-knowledge-workers-using-chat-gpt-outperform)
- **Credibility:** High
- **How to use:** This complicates the narrative—AI *can* help underperformers catch up, but only on tasks where AI is reliable. The frontier detection problem remains.

### 6. Centaurs and Cyborgs

**Finding:** Researchers found two successful AI integration strategies:
- **Centaurs:** Divide and delegate activities—some to AI, some to themselves
- **Cyborgs:** Fully integrate task flow with AI, continually interacting

- **Source:** [Ethan Mollick's analysis](https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged)
- **Credibility:** High (study co-author)
- **How to use:** Both strategies require knowing when to trust AI. Neither works without judgment about AI's limitations.

---

## Counterpoints or Complications

1. **The skill leveling effect cuts both ways.** AI helps underperformers on within-frontier tasks, which suggests it *could* help new entrants—if they knew which tasks were safe. The problem is frontier detection, not AI use per se.

2. **Study was with experienced consultants.** Even the "novices" in this study had BCG training and some professional experience. True workforce entrants might perform even worse.

3. **The frontier moves.** Today's outside-frontier tasks may be inside-frontier tomorrow. Advice based on current AI limitations may not age well.

4. **758 people at one company.** Strong methodology, but limited to BCG's consulting context. May not generalize to all knowledge work.

---

## Gaps in Research

- No longitudinal data on whether the novice disadvantage persists or resolves with experience
- No data on whether novices *learn* to detect the frontier over time
- Limited exploration of how training could help people identify frontier boundaries

---

## Raw Quotes

> "Consultants using AI finished 12.2% more tasks on average, completed tasks 25.1% more quickly, and produced 40% higher quality results."

> "For tasks 'outside the frontier,' researchers observed a performance decrease because people would 'kind of switch off their brains and follow what AI recommends.'"

> "Novices experienced a 19-percentage-point performance drop when using AI at the jagged frontier where AI was unreliable."

> "The consultants who scored the worst when assessed at the start of the experiment had the biggest jump in their performance, 43%, when they got to use AI."

---

## Sources Consulted

- [Harvard D3 Institute - A New Paradigm for Skill Development](https://d3.harvard.edu/a-new-paradigm-for-skill-development-a-large-scale-bcg-experiment/)
- [HBS Working Paper - Navigating the Jagged Technological Frontier (PDF)](https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf)
- [Legal Dive - Generative AI Provides Significant Boost](https://www.legaldive.com/news/harvard-business-school-study-generative-ai-boston-consulting-group/693973/)
- [Mi3 - Harvard Study on BCG and ChatGPT](https://www.mi-3.com.au/20-09-2023/harvard-business-school-study-bcg-finds-knowledge-workers-using-chat-gpt-outperform)
- [EDRM - Report on the First Scientific Experiment](https://edrm.net/2024/04/report-on-the-first-scientific-experiment-to-test-the-impact-of-generative-ai-on-complex-knowledge-intensive-work/)
- [ResearchGate - Navigating the Jagged Technological Frontier](https://www.researchgate.net/publication/374015542_Navigating_the_Jagged_Technological_Frontier_Field_Experimental_Evidence_of_the_Effects_of_AI_on_Knowledge_Worker_Productivity_and_Quality)
- [Ethan Mollick - Centaurs and Cyborgs on the Jagged Frontier](https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged)
