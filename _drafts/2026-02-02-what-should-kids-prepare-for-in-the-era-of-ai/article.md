---
title: "What Should Kids Prepare For in the Era of AI?"
date: 2026-02-02
status: draft
tags: [ai, parenting, careers, education, workforce, uncertainty]
---

When my kids ask what they should study, I tell them to study whatever makes them happy.

This sounds like good parenting. It's actually a confession. I used to have opinions about career paths. Engineering meant stability and options. Art meant passion projects and crossed fingers. We used to say "engineer" with relief and "artist" with crossed fingers. Now we don't know which way to cross our fingers. "Study STEM" was shorthand for "you'll be fine." Now the old heuristics are scrambled. I'm bullish on coding principles. I'm bullish on creativity. I can't rank them. The honest answer is that I don't know where the world will be in a few years, and "whatever makes you happy" is the best I've got.

Here's what I do know: the uncertainty isn't distributed evenly.

## The Burden Falls on the Wrong People

Mid-career professionals have something hard to automate: tacit knowledge, judgment, context. A senior engineer doesn't just know how to code. She knows which problems are worth solving, how decisions actually get made, why certain elegant approaches fail in practice. This judgment layer sits on years of experience. It's exactly what current AI lacks.

Even under aggressive AGI timelines, established professionals will experience transition, not shock. [Adoption lag](/2026/01/19/the-unbundling-of-work/) protects them. AI capability doesn't equal instant organizational change. By the time AI reshapes their industry, they'll have adapted, pivoted, or retired.

The real uncertainty burden falls on people entering the workforce. And by extension, on the kids we're trying to prepare.

## AI Is a Multiplier

Here's the mental model I keep coming back to: AI amplifies whatever is already there.

Think of it like a power saw. It makes a master carpenter faster. It makes a novice dangerous. The tool doesn't care which one you are.

If you're smart, disciplined, and curious, AI makes you more so. You move faster. You tackle bigger problems. If you're sloppy and weak at reasoning, AI amplifies that too. You produce more garbage, faster, with higher confidence.

Current AI still hallucinates. It sounds confident when it's wrong. It produces plausible nonsense that requires expertise to catch. Someone has to know what "good" looks like. That someone is usually the person who could have done the work themselves, just slower.

This is why experienced people win with AI, at least for now. They can guide the tool, catch its mistakes, and know when to override it. They have something worth multiplying.

## The Catch-22 for New Entrants

People entering the workforce face a brutal paradox.

Everyone around them is using AI. They must use AI to keep pace. But they don't yet have deep skills, taste, or judgment. They don't know what good work looks like.

If they rely heavily on AI, they skip the struggle that builds fundamentals. If they avoid AI, they fall behind everyone who didn't.

The paradox, stated plainly: they don't yet have anything for AI to multiply.

## I've Seen This at Work

When engineers are reward-hacking for ticket completion, you can tell. The code gets merged, the metrics look good, but the quality is poor. You know AI was involved because no human who understood the system would have made those choices.

The downstream effect is worse than the bad code. Senior engineers spend their time reviewing and fixing instead of building. This makes them skeptical of AI. They've seen what happens when people who don't understand the work use tools that don't understand it either.

The spiral: juniors misuse AI, seniors clean up, seniors become skeptical, adoption slows, and the juniors still aren't building fundamentals. Everyone loses.

## The Calculator Came After the Multiplication Tables

This tension isn't entirely new. Schools faced a version of it with calculators in the 1970s and 80s.

The consensus took decades: fundamentals first. Students learn arithmetic (K-5), then get calculators (grades 6-7). Research confirmed the intuition. Premature use creates dependency without understanding. Appropriate use, after fundamentals are established, doesn't harm development and often helps.

The workforce has no equivalent structure. You're expected to use AI tools from day one, before you've developed the judgment to evaluate what they produce. The calculator came after the multiplication tables. AI came before the fundamentals.

## The Evidence Is Worse Than the Theory

A [Harvard/BCG study](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700) tested 758 consultants using GPT-4 on realistic tasks. The headline results were encouraging: AI users completed 12% more tasks, 25% faster, with 40% higher quality.

But when tasks fell outside AI's capability boundary, novices experienced a 19-percentage-point performance drop. They did worse with AI than without it. Experts succeeded by identifying flawed suggestions and rejecting them.

This is the jagged frontier problem. AI is brilliant at some things and confidently wrong about others. The boundary is invisible. You can't know where the frontier is without expertise to evaluate the output. AI is most useful to the people who need it least.

## But Maybe Fundamentals Are Changing

I should steelman the other side.

The "fundamentals first" assumption might be historical rather than necessary. A generation fluent in AI tools from childhood might develop a different kind of judgment, one we can't conceptualize because we're anchored to our own experience. We worried calculators would erode mathematical intuition. Maybe it did. Maybe it didn't matter.

People lost the ability to navigate without GPS. This was fine until it wasn't. Dead zones, failures, moments when you actually need the skill you never built. A small cost for most, catastrophic for a few. The question is whether AI dependency follows the same pattern, or whether the stakes are higher.

And the creative reversal hypothesis (that [creativity becomes more valuable](/2025/09/02/the-human-edge/) as technical execution gets commoditized) has survivorship bias. Top-tier creative work requires depth and taste. But most creative work isn't top-tier. The middle of the creative market is being hollowed out. Stock photography is dying. Generic illustration is dying. Telling kids "be creative" might be accurate at the top of the distribution and catastrophic for the median.

I should also ask: who benefits from the "new entrants are at risk" narrative? Does it serve experienced workers protecting their position? Educators justifying traditional methods? I've thought about this. I don't think it serves anyone in particular. Everyone has a role to fulfill. The experienced workers who might benefit from this narrative are also the ones training the juniors, cleaning up the messes, and worrying about their own kids. There's no cartel here. Just genuine uncertainty.

The honest position is uncertainty.

## The Path Is the Same Regardless

Here's where I've landed: I don't have an AGI prediction, and I don't think it matters.

Dario Amodei thinks AGI might arrive by 2027. Demis Hassabis gives it 50% by 2030. The gap matters less than what both agree on: this is happening faster than most realize, and the disruption will be severe. Whether it's three years or ten, the preparation path is the same.

Value will be derived by smart people at every step until we reach AGI or ASI or whatever comes next. This period is either the destination or the training ground. Either way, the work is the same: develop something worth multiplying.

The people I admire most are both highly creative and deep experts in their domain. The combination. That's always been true, and I don't see why AI changes it.

## What I Tell My Kids

So what do I actually say when my kids ask about careers?

Study whatever makes you happy. I mean it. But also: build something worth multiplying. Develop taste. Go deep somewhere. Learn what good looks like before you let the tools take over.

The skills that make you resilient to AI disruption are exactly the skills that AI makes easy to skip. That's the paradox. It doesn't resolve neatly.

I'm preparing them for uncertainty itself. That's the only thing I'm certain about.
