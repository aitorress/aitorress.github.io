---
title: "What Should Kids Prepare For in the Era of AI?"
date: 2026-02-02
status: draft
tags: [ai, parenting, careers, education, workforce, uncertainty]
---

When my kids ask what they should study, I tell them to study whatever makes them happy.

This sounds like good parenting. It's actually a confession. I used to have opinions about career paths. Engineering meant stability and options. Art meant passion projects and crossed fingers. "Study STEM" was shorthand for "you'll be fine." Now the old heuristics are scrambled. I'm bullish on coding principles. I'm bullish on creativity. I can't rank them. The honest answer is that I don't know where the world is going to be in a couple of years, and "whatever makes you happy" is the best I've got.

Here's what I do know: the uncertainty isn't distributed evenly.

## The Burden Falls on the Wrong People

Mid-career professionals have something that's hard to automate: tacit knowledge, judgment, context. A senior engineer doesn't just know how to code. She knows which problems are worth solving, how decisions actually get made in organizations, why certain elegant approaches fail in practice. This judgment layer sits on top of years of accumulated experience. It's exactly what current AI lacks.

Even under aggressive AGI timelines, established professionals will experience transition, not shock. Adoption lag protects them. AI capability doesn't equal instant organizational change. The bureaucracy moves slowly. The procurement cycles drag on. The "we've always done it this way" meetings continue. By the time AI reshapes their industry, they'll have adapted, pivoted, or retired.

The real uncertainty burden falls on people entering the workforce. And by extension, on the kids we're trying to prepare.

## AI Is a Multiplier, Not a Substitute

Here's the mental model I keep coming back to: AI amplifies whatever is already there.

If you're smart, fast, disciplined, and curious, AI makes you more so. You move faster. You tackle bigger problems. You spend less time on drudgery and more time on judgment calls. If you're sloppy, uncurious, and weak at reasoning, AI amplifies that too. You produce more garbage, faster, with higher confidence.

Current AI still hallucinates. It sounds confident when it's wrong. It produces plausible nonsense that requires expertise to catch. Someone has to know what "good" looks like. Someone has to review the output and reject the bad suggestions. That someone is usually the person who could have done the work themselves, just slower.

This is why experienced people win with AI, at least for now. They already know the domain. They can guide the tool, catch its mistakes, and know when to override it. AI makes them faster because they have something worth multiplying.

## The Catch-22 for New Entrants

People entering the workforce face a brutal paradox.

Everyone around them is using AI. They must use AI to keep pace. Refusing isn't an option when your peers are producing twice as much output. But they don't yet have deep skills. They don't have taste or judgment. They don't know what good work looks like in their field.

If they rely heavily on AI, they skip the struggle that builds fundamentals. If they avoid AI, they fall behind everyone who didn't.

The paradox, stated plainly: they don't yet have anything for AI to multiply.

## I've Seen This at Work

When engineers are reward-hacking for ticket completion, you can tell. The code gets merged, the metrics look good, but the quality is poor. You know AI was involved because no human who understood the system would have made those choices. There was no real review. The AI was misguided and nobody caught it.

The downstream effect is worse than the bad code itself. Senior engineers end up spending their time reviewing and fixing this work instead of building new things. This doesn't make them enthusiastic about AI. It makes them skeptical. They've seen what happens when people who don't understand the work use tools that don't understand it either.

The spiral goes like this: juniors misuse AI, seniors clean up the mess, seniors become skeptical of AI, organizational adoption slows, and the juniors still aren't building the fundamentals they need. Everyone loses.

## The Calculator Came After the Multiplication Tables

This tension isn't entirely new. Schools faced a version of it with calculators in the 1970s and 80s.

The consensus that emerged took decades: fundamentals first. Students learn arithmetic (K-5), then get calculators (grades 6-7). Research confirmed the intuition. Premature calculator use creates dependency without understanding. Appropriate use, after fundamentals are established, doesn't harm mathematical development and often helps it. As one researcher put it, "The use of calculators cannot replace understanding mathematical concepts, skills and human reasoning."

The workforce has no equivalent structure. There's no "fundamentals-first" phase. You're expected to use AI tools from day one, before you've developed the judgment to evaluate what they produce. The calculator came after the multiplication tables. AI came before the fundamentals.

## The Evidence Is Worse Than the Theory

A [Harvard/BCG study](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700) from 2023 tested 758 consultants using GPT-4 on realistic tasks. The headline results were encouraging: AI users completed 12% more tasks, worked 25% faster, and produced 40% higher quality output.

But the researchers also tested what happened outside AI's capability boundary. When the task fell beyond what the AI could reliably do, novices experienced a 19-percentage-point performance drop. They did worse with AI than without it. Experts, meanwhile, succeeded by identifying the flawed suggestions and rejecting them.

This is the jagged frontier problem. AI is brilliant at some things and confidently wrong about others. The boundary between these zones is invisible. You can't know where the frontier is without the expertise to evaluate the output. Which means AI is most useful to the people who need it least.

## But Maybe Fundamentals Are Changing

I should steelman the counterargument.

The "build fundamentals first" assumption might be historical rather than necessary. A generation that grows up fluent in AI tools from childhood might develop a different kind of judgment, one we can't even conceptualize because we're anchored to our own experience. We worried calculators would erode mathematical intuition. Maybe it did. Maybe it didn't matter much.

And the creative reversal hypothesis (that creativity becomes more valuable as technical execution gets commoditized) has survivorship bias baked in. Yes, top-tier creative work requires depth and taste. But most creative work isn't top-tier. The middle of the creative market is already being hollowed out. Stock photography is dying. Generic illustration is dying. Telling kids "be creative" might be accurate at the top of the distribution and catastrophic advice for the median.

The honest position is uncertainty.

## The Path Is the Same Regardless

Here's where I've landed: I don't have an AGI prediction, and I don't think it matters.

Dario Amodei thinks AGI might arrive by 2027. Demis Hassabis gives it a 50% chance by 2030. The gap between those predictions matters less than what both men agree on: this is happening faster than most people realize, and the disruption will be severe. Whether it's three years or ten, the preparation path is the same.

Value will be derived by smart people at every step of this process, all the way until we reach AGI or ASI or whatever comes next. This period is either the destination or the training ground. Either way, the work is the same: develop something worth multiplying.

The people I admire most are both highly creative and deep experts in their domain. Not one or the other. The combination. That's always been true, and I don't see why AI changes it.

## What I Tell My Kids

So what do I actually say when my kids ask about careers?

Study whatever makes you happy. I mean it. But also: build something worth multiplying. Develop taste. Go deep somewhere. Learn what good looks like in a field before you let the tools take over.

The skills that make you resilient to AI disruption are exactly the skills that AI makes easy to skip. That's the paradox. It doesn't resolve neatly.

I'm preparing them for uncertainty itself. That's the only thing I'm certain about.
